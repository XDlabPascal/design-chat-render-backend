// index.js â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ï¿½ï¿½â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import express from 'express';
import cors from 'cors';
import bodyParser from 'body-parser';
import fetch from 'node-fetch';
import nodemailer from 'nodemailer';
import dotenv from 'dotenv';
import { randomBytes } from 'crypto';

dotenv.config();

const app = express();
const PORT = process.env.PORT || 10000;
const FRONTEND_URL = process.env.FRONTEND_URL || '*';
const QUESTIONS_COUNT = Number(process.env.QUESTIONS_COUNT || 5);
const USE_REDIS = Boolean(process.env.REDIS_URL);

let finalSummary = null; // mÃ©moire fallback (local only)

// Si REDIS_URL prÃ©sent, on l'utilise pour stocker l'Ã©tat des jobs (recommandÃ© en prod)
let redis = null;
if (USE_REDIS) {
  try {
    const Redis = (await import('ioredis')).default; // dynamic import to avoid crash if lib missing
    redis = new Redis(process.env.REDIS_URL);
    redis.on('error', (e) => console.error('Redis error:', e));
    console.log('âœ… Redis client initialisÃ©');
  } catch (e) {
    console.error('âŒ Impossible d\'initialiser Redis :', e);
    redis = null;
  }
}

app.use(cors({ origin: FRONTEND_URL === '*' ? true : FRONTEND_URL }));
app.use(bodyParser.json());

// Logging middleware simple
app.use((req, res, next) => {
  console.log(`[HTTP] ${new Date().toISOString()} ${req.method} ${req.originalUrl}`);
  next();
});

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SYSTEM PROMPT MISTRAL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
const SYSTEM_PROMPT = `
Tu es un pÃ©dagogue expert en formation sur le design (UX), et sur l'expÃ©rience client (CX). Tu dois Ã©valuer un chef de produit sur ses connaissances en design et expÃ©rience client, en le tutoyant pour rendre l'Ã©change plus direct et engageant.

Ta mission :

1. Tout d'abord, le front end du chat va poser une 1Ã¨re question pour savoir si lâ€™utilisateur est prÃªt.

1. Ensuite, pose exactement 5 questions pour Ã©valuer son niveau:
   â€¢ Utilise un **mÃ©lange de questions ouvertes et de QCM**, dans cet ordre :
     â€¢ Question 1 = QCM  
     â€¢ Question 2 = question ouverte  
     â€¢ Question 3 = QCM  
     â€¢ Question 4 = question ouverte  
     â€¢ Question 5 = QCM
          
   â€¢ Ã€ partir de la question 1, commence **chaque message par un bref commentaire personnalisÃ© avec donne la bonne rÃ©ponse Ã  la question prÃ©cÃ©dente**, avant de poser la nouvelle question.  
     Exemple : â€œTa rÃ©ponse montre que tu as une bonne intuition. Voyons maintenantâ€¦â€  
     Le commentaire doit Ãªtre court, naturel, pertinent.

2. Pose **une seule question par message**, soit ouverte, soit QCM.  
   Ne mÃ©lange jamais plusieurs questions dans une mÃªme rÃ©ponse.  

3. AprÃ¨s que l'utilisateur ai donnÃ© la rÃ©ponse Ã  Ã  la question 5, affiche dâ€™abord uniquement :
   â³ Merci ! Je prÃ©pare ta synthÃ¨seâ€¦

4. Ensuite, rÃ©dige une **synthÃ¨se structurÃ©e et claire**, toujours en **tutoyant**, contenant les sections suivantes :

### Points forts :  
### Faiblesses :  
### Playlist recommandÃ©e (10 vidÃ©os YouTube en franÃ§ais) :  
- [Titre de la vidÃ©o](https://...)  
### SynthÃ¨se :

Contraintes :
â€¢ Formate chaque QCM comme ceci :  
  Texte de la question ?  
  1. choix 1  
  2. choix 2  
  3. choix 3  
  4. choix 4
  5. choix 5

â€¢ Les questions ouvertes doivent Ãªtre courtes, concrÃ¨tes et adaptÃ©es Ã  son niveau**.  
â€¢ Les commentaires entre questions doivent montrer une progression logique dans lâ€™Ã©valuation.  
â€¢ Ne pose plus aucune question aprÃ¨s la synthÃ¨se.  
â€¢ N'utilise jamais d'abrÃ©viation. 
â€¢ RÃ©ponds toujours en franÃ§ais.  
â€¢ Le ton doit Ãªtre tournÃ© vers le tutoiement**.  
â€¢ Reste bienveillant, clair et synthÃ©tique.  
â€¢ Ne repose plus aucune question aprÃ¨s la synthÃ¨se finale. 
â€¢ RÃ©ponds une seule fois Ã  chaque Ã©tape.
â€¢ Ecris combien il reste de questions.
`;

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ /message â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
app.post('/message', async (req, res) => {
  const { history } = req.body;
  if (!history || !Array.isArray(history) || history.length === 0) {
    return res.status(400).json({ error: 'history manquant ou vide' });
  }

  // nombre de rÃ©ponses utilisateur
  const userCount = history.filter((m) => m.role === 'user').length;
  // on considÃ¨re la fin quand on a atteint QUESTIONS_COUNT rÃ©ponses utilisateur
  const done = userCount >= QUESTIONS_COUNT;

  const payload = {
    model: 'mistral-small-latest',
    temperature: 0.7,
    messages: [{ role: 'system', content: SYSTEM_PROMPT }, ...history],
  };

  try {
    // Appel Ã  Mistral (ou autre LLM)
    const resp = await fetch('https://api.mistral.ai/v1/chat/completions', {
      method : 'POST',
      headers: {
        Authorization: `Bearer ${process.env.MISTRAL_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(payload),
    });

    if (!resp.ok) {
      const txt = await resp.text();
      console.error('Mistral ERROR', resp.status, txt);
      return res.status(500).json({ error: 'Erreur Mistral ' + resp.status });
    }

    const data     = await resp.json();
    const botReply = data.choices?.[0]?.message?.content ?? '';

    // Si on a atteint la fin (done) : gÃ©nÃ©rer la synthÃ¨se (async) si nÃ©cessaire
    if (done) {
      // Si la synthÃ¨se est dÃ©jÃ  incluse dans la rÃ©ponse (selon marker ðŸŽ¯), on la stocke directement
      if (botReply.includes('ðŸŽ¯')) {
        finalSummary = botReply;
      } else {
        // On dÃ©clenche la gÃ©nÃ©ration en background.
        // Deux modes :
        // - Si Redis configurÃ© : crÃ©er un jobId, stocker l'Ã©tat dans Redis (processing) et gÃ©nÃ©rer en background.
        // - Sinon (fallback) : gÃ©nÃ©rer en background puis stocker dans finalSummary (mÃ©moire).
        if (USE_REDIS && redis) {
          const jobId = randomBytes(12).toString('hex');
          await redis.set(`job:${jobId}`, JSON.stringify({ status: 'processing', summary: null }));

          (async () => {
            try {
              // limiter le contexte si nÃ©cessaire
              const shortHistory = history.slice(-12);
              const synthPayload = {
                model: 'mistral-small-latest',
                temperature: 0.7,
                messages: [
                  { role: 'system', content: SYSTEM_PROMPT },
                  ...shortHistory,
                  { role: 'assistant', content: botReply },
                  { role: 'user', content: 'RÃ©dige maintenant la synthÃ¨se finale.' },
                ],
              };

              const synthResp = await fetch('https://api.mistral.ai/v1/chat/completions', {
                method : 'POST',
                headers: {
                  Authorization: `Bearer ${process.env.MISTRAL_API_KEY}`,
                  'Content-Type': 'application/json',
                },
                body: JSON.stringify(synthPayload),
              });

              if (!synthResp.ok) {
                const txt = await synthResp.text();
                console.error('Mistral synthÃ¨se ERROR', synthResp.status, txt);
                await redis.set(`job:${jobId}`, JSON.stringify({ status: 'error', summary: null, error: txt }));
                return;
              }

              const synthData = await synthResp.json();
              const summaryText = synthData.choices?.[0]?.message?.content ?? null;

              if (summaryText) {
                await redis.set(`job:${jobId}`, JSON.stringify({ status: 'done', summary: summaryText }));
                // pour compatibilitÃ© locale on met aussi finalSummary (mais ATTENTION multi-instance)
                finalSummary = summaryText;
              } else {
                await redis.set(`job:${jobId}`, JSON.stringify({ status: 'error', summary: null, error: 'empty summary' }));
              }
            } catch (e) {
              console.error('Async synthÃ¨se fetch failed', e);
              await redis.set(`job:${jobId}`, JSON.stringify({ status: 'error', summary: null, error: e.message }));
            }
          })();

          // on retourne jobId pour que le front puisse le poller (optionnel)
          return res.json({ reply: botReply, done: true, jobId });
        } else {
          // fallback : gÃ©nÃ©ration asynchrone en mÃ©moire (comme avant) â€” attention: pas fiable si plusieurs instances
          (async () => {
            try {
              const shortHistory = history.slice(-12);
              const synthPayload = {
                model: 'mistral-small-latest',
                temperature: 0.7,
                messages: [
                  { role: 'system', content: SYSTEM_PROMPT },
                  ...shortHistory,
                  { role: 'assistant', content: botReply },
                  { role: 'user', content: 'RÃ©dige maintenant la synthÃ¨se finale.' },
                ],
              };

              const synthResp = await fetch('https://api.mistral.ai/v1/chat/completions', {
                method : 'POST',
                headers: {
                  Authorization: `Bearer ${process.env.MISTRAL_API_KEY}`,
                  'Content-Type': 'application/json',
                },
                body: JSON.stringify(synthPayload),
              });

              if (!synthResp.ok) {
                const txt = await synthResp.text();
                console.error('Mistral synthÃ¨se ERROR', synthResp.status, txt);
                return;
              }

              const synthData = await synthResp.json();
              finalSummary = synthData.choices?.[0]?.message?.content ?? null;
            } catch (e) {
              console.error('Async synthÃ¨se fetch failed', e);
            }
          })();
        }
      }
    }

    // RÃ©ponse immÃ©diate au client (si Redis utilisÃ© et done true, on peut aussi renvoyer jobId plus haut)
    return res.json({ reply: botReply, done });
  } catch (err) {
    console.error(err);
    return res.status(500).json({ error: 'Erreur serveur / fetch' });
  }
});

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ /summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
// IMPORTANT: toujours renvoyer 200 avec { summary: null } quand synthÃ¨se pas prÃªte.
// Si Redis est utilisÃ© et qu'un jobId est fourni, on renvoie l'Ã©tat du job.
app.get('/summary', async (req, res) => {
  try {
    const jobId = req.query.jobId;

    if (USE_REDIS && redis) {
      if (jobId) {
        const data = await redis.get(`job:${jobId}`);
        if (!data) {
          // job absent ou pas encore initialisÃ©
          return res.json({ summary: null });
        }
        const parsed = JSON.parse(data);
        if (parsed.status === 'processing') return res.json({ summary: null });
        if (parsed.status === 'done') return res.json({ summary: parsed.summary });
        // status error -> renvoyer 500 avec message d'erreur
        return res.status(500).json({ error: parsed.error || 'Erreur interne job' });
      } else {
        // pas de jobId : renvoyer fallback global (compatibilitÃ©)
        return res.json({ summary: finalSummary || null });
      }
    }

    // fallback sans Redis : retour en mÃ©moire (dev / mono-instance)
    return res.json({ summary: finalSummary || null });
  } catch (err) {
    console.error('Error in /summary:', err);
    return res.status(500).json({ error: 'internal' });
  }
});

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ /send-email â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
app.post('/send-email', async (req, res) => {
  const { email } = req.body;
  if (!email || !finalSummary) {
    return res.status(400).json({ error: 'Email ou synthÃ¨se absente' });
  }

  try {
    const transporter = nodemailer.createTransport({
      host: 'smtp.gmail.com',
      port: 465,
      secure: true,
      auth: {
        user: process.env.EMAIL_USER,
        pass: process.env.EMAIL_PASS,
      },
    });

    await transporter.sendMail({
      from: process.env.EMAIL_USER,
      to: email,
      subject: 'Ton Ã©valuation en design.',
      text: finalSummary,
    });

    res.json({ success: true });
  } catch (e) {
    console.error(e);
    res.status(500).json({ error: 'Envoi email Ã©chouÃ©' });
  }
});

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ endpoint racine â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
app.get('/', (req, res) => {
  res.send('âœ… Backend Design-Chat opÃ©rationnel');
});

app.listen(PORT, () => {
  console.log(`âœ… Serveur lancÃ© sur http://localhost:${PORT} (port ${PORT})`);
});
